<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="..\..\CSS\bootstrap.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script src="..\..\JavaScript\search.js"></script>
    <title>Vacuum Cleaners: Mapping</title>
</head>
<body>
<div id="main">
    <div class="container-fluid" id="top">
        <nav class="navbar navbar-inverse navbar-fixed-top">
            <a class="navbar-brand active" href="..\..\Home.html">Home</a>
            <ul class="nav navbar-nav">
                <li><a href="..\Machine Learning\Machine Learning.html">Machine Learning</a></li>
                <li><a href="..\History\History.html">History</a></li>
                <li><a href="..\Significance\Significance.html">Significance</a></li>
                <li><a href="..\Folding Robots\Home.html">Laundry Robots</a></li>
                <li class="dropdown active"><a href="..\Vacuum\Home.html">Vacuum Robots<span class="caret"></span></a>
                    <ul class="dropdown-menu">
                        <li><a href="..\Vacuum\Home.html">Random Vacuuming</a></li>
                        <li><a href="..\Vacuum\SLAM.html">Mapping Vacuuming</a></li>
                    </ul>
                </li>
                <li><a href="..\Grasping Robots\Grasping Robots.html">Grasping</a></li>
            </ul>
            <form class="navbar-form navbar-right" role="search">
                <div class="input-group">
                    <input id="search-bar" type="text" class="form-control" placeholder="Search">
                    <div class="input-group-btn">
                        <button id="search-button" type="submit" class="btn btn-default">Submit</button>
                    </div>
                </div>
            </form>
        </nav>
    </div>
    <div class="container-fluid" id="content">
        <div class="row" id="text">
            <h1>Mapping Cleaning Robots</h1>
            <p><h4><b>How Vacuum Cleaners Use SLAM</b></h4></p>
            <br>
        </div>
        <div class="row">
            <div id="text" class="col-md-8 text-justify">
                <p><h4><b>What is SLAM?</b></h4></p>
                <p>SLAM is an acronym for “Simultaneous Localisation and Mapping.” It’s a computational problem in which a robot must build a map of its environment and find its location within the map using visual information it collects with an assortment of sensors. (1,2)⁠</p>
                <p><h4><b>How does it work?</b></h4></p>
                <p>Automated vacuum cleaners use different forms of imaging in order to build a virtual map of the room around them. They do this by detecting their distance away from “landmarks” (like the corners of tables) and continuously calculating these distances as they move about the room to find their location within the virtual map.</p>
                <p>Some vacuum cleaners use cameras to analyze their surroundings, along with a SLAM algorithm, to clean a room. For example, the Dyson EYE uses a single 360 degree camera to estimate its position in a room, it can also evaluate where it has already cleaned. MonoSLAM is the algorithm used in Dyson EYE (and for single camera SLAM.) (3)⁠</p>

                <p><h4><b>Why is it Important?</b></h4></p>
                <p>SLAM is important simply for the reason that all mobile robots need to be able to function in an environment they haven’t seen before. In vacuum cleaners it’s especially important to be able to determine the nature of the environment to avoid situations in which they inadequately clean the room. SLAM will prevent autonomous vacuum cleaners from vacuuming over spots they’ve already cleaned, or missing spots entirely, allowing for a more accurate and comprehensive vacuum.</p>
                <p>In the future, perfect implementations of SLAM could allow totally autonomous robotic vehicles to be placed in unknown environments and still function as expected. (2)</p>
                <p><h4><b>SLAM in Depth</b></h4></p>
                <p>Although there isn’t one single way to implement SLAM, as different hardware calls for different algorithms, the general process goes as follows; Robots will scan the environment for landmarks. They will then determine their distance away from these landmarks using a variety of methods. One potential method could be using an offset between two cameras to detect depth, similar to the human eye. After traversing the environment, the robot can begin to build a virtual map of its location and place itself within that map by scanning once more to identify how much the landmarks have been displaced so it can calculate depth, and will also add any new landmarks it comes across. It can then estimate its movement within the map and check if it corresponds with the landmarks it has already seen. If not, it can adjust its position within the virtual map to correct itself. (1,2,4)⁠
                </p>
                <p>As mentioned before, SLAM uses multiple methods to estimate the distance between the landmarks and the robot. These estimates are added to form what is called a “probabilistic 3D map”. This is a map of the environment which takes into account the uncertainty of the readings of the distance to the landmarks. The robot can then estimate the location of its camera in this 3D map that it is building. (4,5)⁠⁠
                </p>
                <p>The Dyson EYE uses a single 360 degree camera (therefore implementing MonoSLAM) to vacuum a room.(3)⁠ This allows the Dyson EYE to operate using only one camera. This is incredibly useful in home robotics, given that the manufacturer doesn’t have to include multiple cameras, which would increase bulk and price, so it is more convenient and cheaper to produce and is much more convenient for the user since it is compact and affordable (you don't want a factory sized robot in your house.) Along with being cheaper, the vacuum would be less bulky and therefore more maneuverable, allowing it to reach more places to vacuum (such as between chair legs or under short tables.) MonoSLAM is similar to the general solution of SLAM, however, with only one camera it becomes difficult to measure the distance to landmarks since it cannot be done with just one shot from the camera.(6)⁠ MonoSLAM is unable to compare things such as the offset between multiple cameras, and so must resort to alternative methods. The depth can however be found as the camera moves by creating a line from the camera’s position in the map in the direction of the landmark on which the landmark must lie. As the robot moves and scans its surroundings again, the landmark is seen once more, and the robot determines that its 3D position must lie along the line created in the last step, so it is able to collect depth information about the object and get a closer approximation of its 3D location in the map.(6)⁠
                </p>
                <p>SLAM is very complex, a lot more complex than explained here, however the benefits are clear. It allows robots to be set in new environments and still be able to traverse them despite having little to no knowledge about the environment they’re in. The increased computing power necessary and complex algorithms required (especially in MonoSLAM) are worth the payoff, though, as it’s certainly more efficient for home robotics than random motion like we saw in the <a href="..\Vacuum\Home.html">Roomba.</a>
                </p>
            </div>
            <div id="image" class="col-md-4">
                <br>
                <br>
                <img src="dyson.gif" class="img-responsive"/>
                Animated demonstration of a Dyson EYE in operation. (7)
                <a href="http://www.wired.com/wp-content/uploads/2014/09/Dyson-21.gif">Source</a>
            </div>
        </div>
    </div>
    <div class="container-fluid" id="references">
        <b>Reference List:</b>
        <p>1. 	Durrant-Whyte H, Bailey T. Simultaneous localization and mapping (SLAM): part I The Essential Algorithms. Robot Autom Mag. 2006;2:99–110.</p>
        <p>2. 	Dissanayake MWMG, Newman P, Clark S, Durrant-Whyte HF, Csorba M. A Solution to the Simultaneous Localisation and Map Building (SLAM) Problem. [cited 2017 Mar 10]; Available from: http://www.cs.cmu.edu/~./16-899/notes/slam_ieee.pdf</p>
        <p>3. 	Ackerman E. Dyson’s Robot Vacuum Has 360-Degree Camera, Tank Treads, Cyclone Suction - IEEE Spectrum [Internet]. 2014 [cited 2017 Mar 8]. Available from: http://spectrum.ieee.org/automaton/robotics/home-robots/dyson-the-360-eye-robot-vacuum</p>
        <p>4. 	Riisgaard S, Blas MR. SLAM for Dummies A Tutorial Approach to Simultaneous Localization and Mapping By the “dummies.” [cited 2017 Mar 10]; Available from: https://ocw.mit.edu/courses/aeronautics-and-astronautics/16-412j-cognitive-robotics-spring-2005/projects/1aslam_blas_repo.pdf</p>
        <p>5. 	Hornung A, Wurm KM, Bennewitz M, Stachniss C, Burgard W. OctoMap: An Efficient Probabilistic 3D Mapping Framework Based on Octrees. [cited 2017 Mar 15]; Available from: http://www2.informatik.uni-freiburg.de/~hornunga/pub/hornung13auro.pdf</p>
        <p>6. 	Davison AJ, Reid ID, Molton ND, Stasse O. MonoSLAM: Real-time single camera SLAM. IEEE Trans Pattern Anal Mach Intell. 2007;29(6):1052–67.</p>
        <p>7.  http://www.wired.com/wp-content/uploads/2014/09/Dyson-21.gif [accessed 28 February 2017]</p>
    </div>

</div>
</body>
</html>